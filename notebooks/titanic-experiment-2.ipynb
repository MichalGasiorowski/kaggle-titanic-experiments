{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.4\r\n"
     ]
    }
   ],
   "source": [
    "from copyreg import pickle\n",
    "!python -V"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MLflow setup:\n",
    "\n",
    "To run this example you need to launch the mlflow server locally by running the following command in your terminal:\n",
    "\n",
    "`mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0 --port 5000`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from toolz import compose\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from matplotlib_inline import backend_inline\n",
    "\n",
    "import warnings\n",
    "\n",
    "backend_inline.set_matplotlib_formats('svg')\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "_data_root = os.path.join(\"./../\", 'data')\n",
    "_data_root_raw = os.path.join(_data_root, 'raw')\n",
    "_data_root_processed =  os.path.join(_data_root, 'processed')\n",
    "\n",
    "_train_dirpath = os.path.join(_data_root_raw, \"train\")\n",
    "_train_filepath = os.path.join(_train_dirpath, \"train.csv\")\n",
    "_test_dirpath = os.path.join(_data_root_raw, \"test\")\n",
    "_test_filepath = os.path.join(_test_dirpath, \"test.csv\")\n",
    "\n",
    "_train_processed_dirpath = os.path.join(_data_root_processed, \"train\")\n",
    "_train_processed_filepath = os.path.join(_data_root_processed, \"train.csv\")\n",
    "_valid_processed_dirpath = os.path.join(_data_root_processed, \"valid\")\n",
    "_valid_processed_filepath = os.path.join(_data_root_processed, \"valid.csv\")\n",
    "_test_processed_dirpath = os.path.join(_data_root_processed, \"test\")\n",
    "_test_processed_filepath = os.path.join(_data_root_processed, \"test.csv\")\n",
    "\n",
    "os.makedirs(_train_dirpath, exist_ok=True)\n",
    "os.makedirs(_test_dirpath, exist_ok=True)\n",
    "os.makedirs(_train_processed_dirpath, exist_ok=True)\n",
    "os.makedirs(_valid_processed_dirpath, exist_ok=True)\n",
    "os.makedirs(_test_processed_dirpath, exist_ok=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download data from kaggle, unzip it and copy it to data folder\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    !kaggle competitions download -c titanic -p {_data_root} --force\n",
    "    !unzip -o {_data_root}/\"titanic.zip\" -d {_data_root}\n",
    "    !cp {_data_root}/\"train.csv\" {_train_filepath}\n",
    "    !cp {_data_root}/\"test.csv\" {_test_filepath}\n",
    "\n",
    "    # clean up\n",
    "    !rm  {_data_root}/*.csv  {_data_root}/*.zip\n",
    "\n",
    "def extract_target(data: pd.DataFrame, target=\"Survived\"):\n",
    "    targets = data[target].values\n",
    "    return targets\n",
    "\n",
    "def preprocess_df(df: pd.DataFrame, transforms, categorical, numerical):\n",
    "    \"\"\"Return processed features dict and target.\"\"\"\n",
    "\n",
    "    # Apply in-between transformations\n",
    "    df = compose(*transforms[::-1])(df)\n",
    "\n",
    "    # For dict vectorizer: int = ignored, str = one-hot\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    # Convert dataframe to feature dictionaries\n",
    "    feature_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    return feature_dicts\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"Return processed features dict and target.\"\"\"\n",
    "\n",
    "    # Load dataset\n",
    "    if filename.endswith('parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "    elif filename.endswith('csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        raise \"Error: not supported file format.\"\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess(df: pd.DataFrame, dv: DictVectorizer, fit_dv: bool = False):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    if fit_dv:\n",
    "        X = dv.fit_transform(dicts)\n",
    "    else:\n",
    "        X = dv.transform(dicts)\n",
    "    return X, dv\n",
    "\n",
    "def preprocess_no_extract_target(filename, transforms, categorical, numerical):\n",
    "    df = read_data(filename)\n",
    "\n",
    "    feature_dicts = preprocess_df(df, transforms, categorical, numerical)\n",
    "\n",
    "    return feature_dicts\n",
    "\n",
    "def split_train_read(filename: str, val_size=0.2, random_state=42):\n",
    "    df_train_full = read_data(filename)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train_full, test_size=val_size, random_state=random_state)\n",
    "    return df_train, df_val\n",
    "\n",
    "def save_preprocessed(df: pd.DataFrame, path):\n",
    "    df.to_csv(path)\n",
    "\n",
    "def dump_pickle(obj, filename):\n",
    "    with open(filename, \"wb\") as f_out:\n",
    "        return pickle.dump(obj, f_out)\n",
    "\n",
    "def run():\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "    mlflow.set_experiment(\"titanic-experiment\")\n",
    "    mlflow.autolog()\n",
    "    with mlflow.start_run():\n",
    "        download_data()\n",
    "        transforms = []\n",
    "        target = 'Survived'\n",
    "        categorical = ['Sex', 'Pclass', 'Embarked', 'SibSp', 'Parch']\n",
    "        numerical = ['Fare']\n",
    "\n",
    "        df_train, df_val = split_train_read(_train_filepath, val_size=0.2, random_state=42)\n",
    "\n",
    "        train_dicts, y_train = preprocess_df(df_train, transforms, categorical, numerical), extract_target(df_train)\n",
    "        val_dicts, y_val = preprocess_df(df_val, transforms, categorical, numerical), extract_target(df_val)\n",
    "\n",
    "        df_test = read_data(_test_filepath)\n",
    "        test_dicts = preprocess_df(df_test, transforms, categorical, numerical)\n",
    "\n",
    "        # Fit all possible categories\n",
    "        dv = DictVectorizer()\n",
    "        dv.fit(train_dicts)\n",
    "\n",
    "        X_train = dv.transform(train_dicts)\n",
    "        X_val = dv.transform(val_dicts)\n",
    "        X_test = dv.transform(test_dicts)\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        dump_pickle(model, os.path.join(\"../models\", \"rfc.pkl\"))\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        accuracy = np.round(accuracy_score(y_val, y_pred), 4)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_artifact(local_path=os.path.join(\"../models\", \"rfc.pkl\"), artifact_path=\"models_pickle\")\n",
    "        print(accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/07/22 20:07:03 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading titanic.zip to ./../data\r\n",
      "  0%|                                               | 0.00/34.1k [00:00<?, ?B/s]\r\n",
      "100%|██████████████████████████████████████| 34.1k/34.1k [00:00<00:00, 1.91MB/s]\r\n",
      "Archive:  ./../data/titanic.zip\r\n",
      "  inflating: ./../data/gender_submission.csv  \r\n",
      "  inflating: ./../data/test.csv      \r\n",
      "  inflating: ./../data/train.csv     \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/07/22 20:07:10 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/michal/.local/share/virtualenvs/kaggle-titanic-experiments-_bPcWiX9/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8045\n"
     ]
    }
   ],
   "source": [
    "run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}