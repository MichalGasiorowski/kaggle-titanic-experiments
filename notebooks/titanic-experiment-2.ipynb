{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.4\r\n"
     ]
    }
   ],
   "source": [
    "from copyreg import pickle\n",
    "!python -V"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MLflow setup:\n",
    "\n",
    "To run this example you need to launch the mlflow server locally by running the following command in your terminal:\n",
    "\n",
    "`mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0 --port 5000`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To start MLflow Tracking Server enabled with proxied artifact storage access:\n",
    "( see more in : [https://www.mlflow.org/docs/latest/tracking.html#where-runs-are-recorded](https://www.mlflow.org/docs/latest/tracking.html#where-runs-are-recorded) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "'mlflow server --host 0.0.0.0 --port 5000 --serve-artifacts --artifacts-destination s3://mlflow-enkidupal-experiments/'"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3_BUCKET = 's3://mlflow-enkidupal-experiments'\n",
    "f'mlflow server --host 0.0.0.0 --port 5000 --serve-artifacts --artifacts-destination {S3_BUCKET}/'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To rerun the server, this command has to be run in *correct* directory,\n",
    "where previous mlflow server was run, to point backend-store-uri to mlflow.db !\n",
    "\n",
    "`cd project_root`\n",
    "\n",
    "\n",
    " `mlflow server --host 0.0.0.0 --port 5000 --serve-artifacts --artifacts-destination s3://mlflow-enkidupal-experiments/`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from toolz import compose\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from matplotlib_inline import backend_inline\n",
    "\n",
    "import warnings\n",
    "\n",
    "backend_inline.set_matplotlib_formats('svg')\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "_data_root = os.path.join(\"./../\", 'data')\n",
    "_data_root_raw = os.path.join(_data_root, 'raw')\n",
    "_data_root_processed =  os.path.join(_data_root, 'processed')\n",
    "\n",
    "_train_dirpath = os.path.join(_data_root_raw, \"train\")\n",
    "_train_filepath = os.path.join(_train_dirpath, \"train.csv\")\n",
    "_test_dirpath = os.path.join(_data_root_raw, \"test\")\n",
    "_test_filepath = os.path.join(_test_dirpath, \"test.csv\")\n",
    "\n",
    "_train_processed_dirpath = os.path.join(_data_root_processed, \"train\")\n",
    "_train_processed_filepath = os.path.join(_data_root_processed, \"train.csv\")\n",
    "_valid_processed_dirpath = os.path.join(_data_root_processed, \"valid\")\n",
    "_valid_processed_filepath = os.path.join(_data_root_processed, \"valid.csv\")\n",
    "_test_processed_dirpath = os.path.join(_data_root_processed, \"test\")\n",
    "_test_processed_filepath = os.path.join(_data_root_processed, \"test.csv\")\n",
    "\n",
    "os.makedirs(_train_dirpath, exist_ok=True)\n",
    "os.makedirs(_test_dirpath, exist_ok=True)\n",
    "os.makedirs(_train_processed_dirpath, exist_ok=True)\n",
    "os.makedirs(_valid_processed_dirpath, exist_ok=True)\n",
    "os.makedirs(_test_processed_dirpath, exist_ok=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download data from kaggle, unzip it and copy it to data folder\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    !kaggle competitions download -c titanic -p {_data_root} --force\n",
    "    !unzip -o {_data_root}/\"titanic.zip\" -d {_data_root}\n",
    "    !cp {_data_root}/\"train.csv\" {_train_filepath}\n",
    "    !cp {_data_root}/\"test.csv\" {_test_filepath}\n",
    "\n",
    "    # clean up\n",
    "    !rm  {_data_root}/*.csv  {_data_root}/*.zip\n",
    "\n",
    "def extract_target(data: pd.DataFrame, target=\"Survived\"):\n",
    "    targets = data[target].values\n",
    "    return targets\n",
    "\n",
    "def preprocess_df_2(df: pd.DataFrame, transforms, categorical, numerical):\n",
    "    \"\"\"Return processed features dict and target.\"\"\"\n",
    "\n",
    "    # Apply in-between transformations\n",
    "    df = compose(*transforms[::-1])(df)\n",
    "\n",
    "    # For dict vectorizer: int = ignored, str = one-hot\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocess_df(df: pd.DataFrame, transforms, categorical, numerical):\n",
    "    \"\"\"Return processed features dict and target.\"\"\"\n",
    "\n",
    "    # Apply in-between transformations\n",
    "    df = compose(*transforms[::-1])(df)\n",
    "\n",
    "    # For dict vectorizer: int = ignored, str = one-hot\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    # Convert dataframe to feature dictionaries\n",
    "    feature_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    return feature_dicts\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"Return processed features dict and target.\"\"\"\n",
    "\n",
    "    # Load dataset\n",
    "    if filename.endswith('parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "    elif filename.endswith('csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "    else:\n",
    "        raise \"Error: not supported file format.\"\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_no_extract_target(filename, transforms, categorical, numerical):\n",
    "    df = read_data(filename)\n",
    "\n",
    "    feature_dicts = preprocess_df(df, transforms, categorical, numerical)\n",
    "\n",
    "    return feature_dicts\n",
    "\n",
    "def split_train_read(filename: str, val_size=0.2, random_state=42):\n",
    "    df_train_full = read_data(filename)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train_full, test_size=val_size, random_state=random_state)\n",
    "    return df_train, df_val\n",
    "\n",
    "def save_preprocessed(df: pd.DataFrame, path):\n",
    "    df.to_csv(path)\n",
    "\n",
    "def dump_pickle(obj, filename):\n",
    "    with open(filename, \"wb\") as f_out:\n",
    "        return pickle.dump(obj, f_out)\n",
    "\n",
    "def run():\n",
    "    mlflow.set_tracking_uri(\"http://0.0.0.0:5000\")\n",
    "    mlflow.set_experiment(\"titanic-experiment\")\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        download_data()\n",
    "        transforms = []\n",
    "        target = 'Survived'\n",
    "        categorical = ['Sex', 'Pclass', 'Embarked', 'SibSp', 'Parch']\n",
    "        numerical = ['Fare']\n",
    "\n",
    "        df_train, df_val = split_train_read(_train_filepath, val_size=0.2, random_state=42)\n",
    "\n",
    "        train_dicts, y_train = preprocess_df(df_train, transforms, categorical, numerical), extract_target(df_train)\n",
    "        val_dicts, y_val = preprocess_df(df_val, transforms, categorical, numerical), extract_target(df_val)\n",
    "\n",
    "        df_test = read_data(_test_filepath)\n",
    "        test_dicts = preprocess_df(df_test, transforms, categorical, numerical)\n",
    "\n",
    "        # Fit all possible categories\n",
    "        dv = DictVectorizer()\n",
    "        dv.fit(train_dicts)\n",
    "\n",
    "        X_train = dv.transform(train_dicts)\n",
    "        X_val = dv.transform(val_dicts)\n",
    "        X_test = dv.transform(test_dicts)\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        with open(\"../models/preprocessor.b\", \"wb\") as f_out:\n",
    "            pickle.dump(dv, f_out)\n",
    "        mlflow.log_artifact(\"../models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "        #    mlflow.xgboost.log_model(booster, artifact_path=\"models_mlflow\")\n",
    "        #mlflow.log_artifact(local_path=os.path.join(\"../models\", \"rfc.pkl\"), artifact_path=\"models_pickle\")\n",
    "        mlflow.sklearn.log_model(model, artifact_path=\"models_pickle\")\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        accuracy = np.round(accuracy_score(y_val, y_pred), 4)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        print(accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "       Sex  Pclass  Embarked  SibSp  Parch\n375  False   False     False  False  False\n344  False   False     False  False  False\n526  False   False     False  False  False\n24   False   False     False  False  False\n234  False   False     False  False  False\n..     ...     ...       ...    ...    ...\n71   False   False     False  False  False\n106  False   False     False  False  False\n270  False   False     False  False  False\n435  False   False     False  False  False\n102  False   False     False  False  False\n\n[569 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Pclass</th>\n      <th>Embarked</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>375</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>526</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>234</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>435</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms = []\n",
    "target = 'Survived'\n",
    "categorical = ['Sex', 'Pclass', 'Embarked', 'SibSp', 'Parch']\n",
    "numerical = ['Fare']\n",
    "\n",
    "df_train, df_val = split_train_read(_train_filepath, val_size=0.2, random_state=42)\n",
    "df_train_preprocessed = preprocess_df_2(df_train, transforms, categorical, numerical)\n",
    "\n",
    "df_train_preprocessed[categorical].head()\n",
    "\n",
    "df_train_preprocessed[categorical].isna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0  PassengerId  Survived  Pclass  \\\n375         517          518         0       3   \n344         792          793         0       3   \n526         472          473         1       2   \n24          483          484         1       3   \n234           9           10         1       2   \n\n                                        Name     Sex   Age  SibSp  Parch  \\\n375                        Ryan, Mr. Patrick    male   NaN      0      0   \n344                  Sage, Miss. Stella Anna  female   NaN      8      2   \n526  West, Mrs. Edwy Arthur (Ada Mary Worth)  female  33.0      1      2   \n24                    Turkula, Mrs. (Hedwig)  female  63.0      0      0   \n234      Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1      0   \n\n         Ticket     Fare Cabin Embarked  \n375      371110  24.1500   NaN        Q  \n344    CA. 2343  69.5500   NaN        S  \n526  C.A. 34651  27.7500   NaN        S  \n24         4134   9.5875   NaN        S  \n234      237736  30.0708   NaN        C  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>375</th>\n      <td>517</td>\n      <td>518</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Ryan, Mr. Patrick</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>371110</td>\n      <td>24.1500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>792</td>\n      <td>793</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Sage, Miss. Stella Anna</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>2</td>\n      <td>CA. 2343</td>\n      <td>69.5500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>526</th>\n      <td>472</td>\n      <td>473</td>\n      <td>1</td>\n      <td>2</td>\n      <td>West, Mrs. Edwy Arthur (Ada Mary Worth)</td>\n      <td>female</td>\n      <td>33.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>C.A. 34651</td>\n      <td>27.7500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>483</td>\n      <td>484</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Turkula, Mrs. (Hedwig)</td>\n      <td>female</td>\n      <td>63.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4134</td>\n      <td>9.5875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>234</th>\n      <td>9</td>\n      <td>10</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n      <td>female</td>\n      <td>14.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>237736</td>\n      <td>30.0708</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading titanic.zip to ./../data\r\n",
      "  0%|                                               | 0.00/34.1k [00:00<?, ?B/s]\r\n",
      "100%|██████████████████████████████████████| 34.1k/34.1k [00:00<00:00, 1.82MB/s]\r\n",
      "Archive:  ./../data/titanic.zip\r\n",
      "  inflating: ./../data/gender_submission.csv  \r\n",
      "  inflating: ./../data/test.csv      \r\n",
      "  inflating: ./../data/train.csv     \r\n",
      "0.8045\n"
     ]
    }
   ],
   "source": [
    "run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}